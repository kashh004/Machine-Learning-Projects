{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072d44ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tpot in /opt/anaconda3/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /opt/anaconda3/lib/python3.11/site-packages (from tpot) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from tpot) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from tpot) (1.5.2)\n",
      "Requirement already satisfied: deap>=1.2 in /opt/anaconda3/lib/python3.11/site-packages (from tpot) (1.4.1)\n",
      "Requirement already satisfied: update-checker>=0.16 in /opt/anaconda3/lib/python3.11/site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/anaconda3/lib/python3.11/site-packages (from tpot) (4.66.5)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/anaconda3/lib/python3.11/site-packages (from tpot) (2.1.4)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/anaconda3/lib/python3.11/site-packages (from tpot) (1.2.0)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tpot) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.4.1->tpot) (3.5.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from update-checker>=0.16->tpot) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->tpot) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87326624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0          1        17.99         10.38          122.80     1001.0   \n",
      "1          1        20.57         17.77          132.90     1326.0   \n",
      "2          1        19.69         21.25          130.00     1203.0   \n",
      "3          1        11.42         20.38           77.58      386.1   \n",
      "4          1        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
      "0         0.2419  ...         25.38          17.33           184.60   \n",
      "1         0.1812  ...         24.99          23.41           158.80   \n",
      "2         0.2069  ...         23.57          25.53           152.50   \n",
      "3         0.2597  ...         14.91          26.50            98.87   \n",
      "4         0.1809  ...         22.54          16.67           152.20   \n",
      "\n",
      "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data_path = '/Users/akashngowda/Downloads/breast+cancer+wisconsin+diagnostic/wdbc.data'\n",
    "column_names = ['ID', 'Diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', \n",
    "                'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave_points_mean', \n",
    "                'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', \n",
    "                'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave_points_se', \n",
    "                'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', \n",
    "                'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', \n",
    "                'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "data = pd.read_csv(data_path, header=None, names=column_names)\n",
    "\n",
    "# Drop the 'ID' column as it's not useful for modeling\n",
    "data.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "# Convert the 'Diagnosis' column to numerical (M = 1, B = 0)\n",
    "data['Diagnosis'] = data['Diagnosis'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "\n",
    "# Check the first few rows of the data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1cd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop('Diagnosis', axis=1)\n",
    "y = data['Diagnosis']\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0b63cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/300 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.9736263736263737\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9736263736263737\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.9736263736263737\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.9758241758241759\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.9780219780219781\n",
      "\n",
      "Best pipeline: DecisionTreeClassifier(GradientBoostingClassifier(input_matrix, learning_rate=0.5, max_depth=7, max_features=0.1, min_samples_leaf=20, min_samples_split=18, n_estimators=100, subsample=0.9500000000000001), criterion=gini, max_depth=5, min_samples_leaf=20, min_samples_split=13)\n",
      "Test Accuracy: 0.9736842105263158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "# Initialize the TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, random_state=42)\n",
    "\n",
    "# Fit the TPOT model on the training data\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "accuracy = tpot.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Export the best pipeline\n",
    "tpot.export('best_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0247eb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.965034965034965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('/Users/akashngowda/Downloads/breast+cancer+wisconsin+diagnostic/wdbc_final_cleaned.csv')\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# The best pipeline discovered by TPOT\n",
    "exported_pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier(n_estimators=100)\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "exported_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Test accuracy\n",
    "print(f\"Test accuracy: {exported_pipeline.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5592c1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.4.1-cp311-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.19.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: higher in /opt/anaconda3/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torch-2.4.1-cp311-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "Using cached torchvision-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (1.7 MB)\n",
      "Installing collected packages: torch, torchvision\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.4.0 requires torch==2.4.0, but you have torch 2.4.1 which is incompatible.\n",
      "vllm 0.6.2 requires torch==2.4.0, but you have torch 2.4.1 which is incompatible.\n",
      "vllm 0.6.2 requires torchvision==0.19, but you have torchvision 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.4.1 torchvision-0.19.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9db459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import higher\n",
    "\n",
    "# Define a simple neural network (this will be adapted for each task)\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(30, 100)  # 30 features for the heart dataset\n",
    "        self.fc2 = nn.Linear(100, 2)   # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# MAML Training Loop\n",
    "def train_maml(model, train_data, meta_lr=0.001, inner_lr=0.01, inner_steps=5):\n",
    "    meta_optimizer = optim.Adam(model.parameters(), lr=meta_lr)\n",
    "\n",
    "    for meta_batch in train_data:\n",
    "        meta_optimizer.zero_grad()\n",
    "\n",
    "        # Inner loop (task-specific learning)\n",
    "        with higher.innerloop_ctx(model, meta_optimizer) as (fmodel, diffopt):\n",
    "            for step in range(inner_steps):\n",
    "                task_loss = nn.CrossEntropyLoss()(fmodel(meta_batch['X_train']), meta_batch['y_train'])\n",
    "                diffopt.step(task_loss)\n",
    "\n",
    "            # Meta-update on validation task\n",
    "            val_loss = nn.CrossEntropyLoss()(fmodel(meta_batch['X_val']), meta_batch['y_val'])\n",
    "            val_loss.backward()\n",
    "\n",
    "        meta_optimizer.step()\n",
    "\n",
    "# Example to run the MAML loop\n",
    "model = SimpleNet()\n",
    "train_data = []  # Load your few-shot tasks here\n",
    "train_maml(model, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09978f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple Prototypical Network\n",
    "class PrototypicalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrototypicalNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(30, 100)  # Feature extraction for heart disease\n",
    "        self.fc2 = nn.Linear(100, 64)  # Output 64-dim embeddings\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def compute_prototypes(embeddings, labels, num_classes):\n",
    "    prototypes = []\n",
    "    for c in range(num_classes):\n",
    "        class_embeddings = embeddings[labels == c]\n",
    "        prototypes.append(class_embeddings.mean(dim=0))\n",
    "    return torch.stack(prototypes)\n",
    "\n",
    "def prototypical_loss(embeddings, prototypes, labels):\n",
    "    distances = torch.cdist(embeddings, prototypes)\n",
    "    return nn.CrossEntropyLoss()(distances, labels)\n",
    "\n",
    "# Example training loop for Prototypical Networks\n",
    "model = PrototypicalNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for batch in train_data:  # Load few-shot tasks here\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    embeddings = model(batch['X_train'])\n",
    "    prototypes = compute_prototypes(embeddings, batch['y_train'], num_classes=2)\n",
    "\n",
    "    val_embeddings = model(batch['X_val'])\n",
    "    loss = prototypical_loss(val_embeddings, prototypes, batch['y_val'])\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54618be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_few_shot_tasks(X, y, num_tasks=100, k_shot=5, val_shot=15):\n",
    "    tasks = []\n",
    "    for _ in range(num_tasks):\n",
    "        classes = np.unique(y)\n",
    "        task_data = {'X_train': [], 'y_train': [], 'X_val': [], 'y_val': []}\n",
    "\n",
    "        for c in classes:\n",
    "            class_idx = np.where(y == c)[0]\n",
    "            np.random.shuffle(class_idx)\n",
    "\n",
    "            # K-shot training examples\n",
    "            train_idx = class_idx[:k_shot]\n",
    "            val_idx = class_idx[k_shot:k_shot+val_shot]\n",
    "\n",
    "            task_data['X_train'].append(X.iloc[train_idx])\n",
    "            task_data['y_train'].append(y.iloc[train_idx])\n",
    "            task_data['X_val'].append(X.iloc[val_idx])\n",
    "            task_data['y_val'].append(y.iloc[val_idx])\n",
    "\n",
    "        # Convert lists to arrays\n",
    "        task_data['X_train'] = np.vstack(task_data['X_train'])\n",
    "        task_data['y_train'] = np.hstack(task_data['y_train'])\n",
    "        task_data['X_val'] = np.vstack(task_data['X_val'])\n",
    "        task_data['y_val'] = np.hstack(task_data['y_val'])\n",
    "\n",
    "        tasks.append(task_data)\n",
    "    return tasks\n",
    "\n",
    "# Example task creation\n",
    "tasks = create_few_shot_tasks(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b9fcd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.4.1)\n",
      "Requirement already satisfied: higher in /opt/anaconda3/lib/python3.11/site-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dcfd874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(30, 100)  # For the heart dataset, input features = 30\n",
    "        self.fc2 = nn.Linear(100, 2)   # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb996c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Meta-Loss: 0.6403880735859275\n",
      "Epoch 2/100, Meta-Loss: 0.9308562649786473\n",
      "Epoch 3/100, Meta-Loss: 0.7957236555218696\n",
      "Epoch 4/100, Meta-Loss: 0.7264008098957129\n",
      "Epoch 5/100, Meta-Loss: 0.7070604446108336\n",
      "Epoch 6/100, Meta-Loss: 0.6886616857285844\n",
      "Epoch 7/100, Meta-Loss: 0.6641360226556572\n",
      "Epoch 8/100, Meta-Loss: 0.6443643951597187\n",
      "Epoch 9/100, Meta-Loss: 0.6223246230179575\n",
      "Epoch 10/100, Meta-Loss: 0.6019311333269798\n",
      "Epoch 11/100, Meta-Loss: 0.5795696160205261\n",
      "Epoch 12/100, Meta-Loss: 0.5576108132352965\n",
      "Epoch 13/100, Meta-Loss: 0.5355582948648225\n",
      "Epoch 14/100, Meta-Loss: 0.5131139343087853\n",
      "Epoch 15/100, Meta-Loss: 0.48969502350475524\n",
      "Epoch 16/100, Meta-Loss: 0.46930992597088333\n",
      "Epoch 17/100, Meta-Loss: 0.4488978683068126\n",
      "Epoch 18/100, Meta-Loss: 0.4297505177144194\n",
      "Epoch 19/100, Meta-Loss: 0.41053077578661035\n",
      "Epoch 20/100, Meta-Loss: 0.39216539767629\n",
      "Epoch 21/100, Meta-Loss: 0.37666330177220514\n",
      "Epoch 22/100, Meta-Loss: 0.36346853779163213\n",
      "Epoch 23/100, Meta-Loss: 0.3487852602114435\n",
      "Epoch 24/100, Meta-Loss: 0.33653319260221903\n",
      "Epoch 25/100, Meta-Loss: 0.3242570025799796\n",
      "Epoch 26/100, Meta-Loss: 0.3117335508088581\n",
      "Epoch 27/100, Meta-Loss: 0.30204432358499617\n",
      "Epoch 28/100, Meta-Loss: 0.28965966643532737\n",
      "Epoch 29/100, Meta-Loss: 0.2781100503145717\n",
      "Epoch 30/100, Meta-Loss: 0.2703127225395292\n",
      "Epoch 31/100, Meta-Loss: 0.2592105250549503\n",
      "Epoch 32/100, Meta-Loss: 0.25074969738489017\n",
      "Epoch 33/100, Meta-Loss: 0.24148898081388326\n",
      "Epoch 34/100, Meta-Loss: 0.23411715896334498\n",
      "Epoch 35/100, Meta-Loss: 0.22541800379753113\n",
      "Epoch 36/100, Meta-Loss: 0.21907896026503296\n",
      "Epoch 37/100, Meta-Loss: 0.2124059592327103\n",
      "Epoch 38/100, Meta-Loss: 0.20585951236542313\n",
      "Epoch 39/100, Meta-Loss: 0.2003214337863028\n",
      "Epoch 40/100, Meta-Loss: 0.19579791577998548\n",
      "Epoch 41/100, Meta-Loss: 0.19183959157206118\n",
      "Epoch 42/100, Meta-Loss: 0.18637785808183252\n",
      "Epoch 43/100, Meta-Loss: 0.1827599068544805\n",
      "Epoch 44/100, Meta-Loss: 0.17947235761210323\n",
      "Epoch 45/100, Meta-Loss: 0.17595883800648152\n",
      "Epoch 46/100, Meta-Loss: 0.17313599309884012\n",
      "Epoch 47/100, Meta-Loss: 0.17067846970632672\n",
      "Epoch 48/100, Meta-Loss: 0.16862719274125992\n",
      "Epoch 49/100, Meta-Loss: 0.1656875584833324\n",
      "Epoch 50/100, Meta-Loss: 0.1637273483723402\n",
      "Epoch 51/100, Meta-Loss: 0.16282224943861365\n",
      "Epoch 52/100, Meta-Loss: 0.16132825624197722\n",
      "Epoch 53/100, Meta-Loss: 0.16025374410673976\n",
      "Epoch 54/100, Meta-Loss: 0.15870570925995708\n",
      "Epoch 55/100, Meta-Loss: 0.15680681105703115\n",
      "Epoch 56/100, Meta-Loss: 0.1562326562218368\n",
      "Epoch 57/100, Meta-Loss: 0.15307376546785234\n",
      "Epoch 58/100, Meta-Loss: 0.15154935408383607\n",
      "Epoch 59/100, Meta-Loss: 0.15283736741170287\n",
      "Epoch 60/100, Meta-Loss: 0.15108468042686582\n",
      "Epoch 61/100, Meta-Loss: 0.1477748497016728\n",
      "Epoch 62/100, Meta-Loss: 0.14769537843763828\n",
      "Epoch 63/100, Meta-Loss: 0.14734381148591638\n",
      "Epoch 64/100, Meta-Loss: 0.1462286195345223\n",
      "Epoch 65/100, Meta-Loss: 0.14635677438229322\n",
      "Epoch 66/100, Meta-Loss: 0.1449069621786475\n",
      "Epoch 67/100, Meta-Loss: 0.1434816428087652\n",
      "Epoch 68/100, Meta-Loss: 0.14150384835898877\n",
      "Epoch 69/100, Meta-Loss: 0.1406765162386\n",
      "Epoch 70/100, Meta-Loss: 0.13973839178681374\n",
      "Epoch 71/100, Meta-Loss: 0.13701615672558545\n",
      "Epoch 72/100, Meta-Loss: 0.13496748795732855\n",
      "Epoch 73/100, Meta-Loss: 0.13517891431227327\n",
      "Epoch 74/100, Meta-Loss: 0.13280128525570034\n",
      "Epoch 75/100, Meta-Loss: 0.13246294537559153\n",
      "Epoch 76/100, Meta-Loss: 0.13265096491202713\n",
      "Epoch 77/100, Meta-Loss: 0.13023873997852206\n",
      "Epoch 78/100, Meta-Loss: 0.13057798840105533\n",
      "Epoch 79/100, Meta-Loss: 0.12853273162618278\n",
      "Epoch 80/100, Meta-Loss: 0.12751278935000301\n",
      "Epoch 81/100, Meta-Loss: 0.12720547096803783\n",
      "Epoch 82/100, Meta-Loss: 0.1249372730217874\n",
      "Epoch 83/100, Meta-Loss: 0.1238689068891108\n",
      "Epoch 84/100, Meta-Loss: 0.12391110872849823\n",
      "Epoch 85/100, Meta-Loss: 0.1232303261756897\n",
      "Epoch 86/100, Meta-Loss: 0.12211779948323966\n",
      "Epoch 87/100, Meta-Loss: 0.12104916037991643\n",
      "Epoch 88/100, Meta-Loss: 0.12043384257704019\n",
      "Epoch 89/100, Meta-Loss: 0.1192440372891724\n",
      "Epoch 90/100, Meta-Loss: 0.11896156350150705\n",
      "Epoch 91/100, Meta-Loss: 0.11731712967157364\n",
      "Epoch 92/100, Meta-Loss: 0.11683745477348566\n",
      "Epoch 93/100, Meta-Loss: 0.1191246878169477\n",
      "Epoch 94/100, Meta-Loss: 0.1163132295385003\n",
      "Epoch 95/100, Meta-Loss: 0.11609539369121194\n",
      "Epoch 96/100, Meta-Loss: 0.11815564382821321\n",
      "Epoch 97/100, Meta-Loss: 0.11708297494798899\n",
      "Epoch 98/100, Meta-Loss: 0.1171782342158258\n",
      "Epoch 99/100, Meta-Loss: 0.11571290168911219\n",
      "Epoch 100/100, Meta-Loss: 0.11363305777311325\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import higher\n",
    "\n",
    "# Define the MAML training loop\n",
    "def train_maml(model, tasks, meta_lr=0.001, inner_lr=0.01, inner_steps=5, meta_epochs=100):\n",
    "    meta_optimizer = optim.Adam(model.parameters(), lr=meta_lr)\n",
    "\n",
    "    for epoch in range(meta_epochs):\n",
    "        total_meta_loss = 0\n",
    "        for task in tasks:\n",
    "            # Zero the meta-optimizer gradient\n",
    "            meta_optimizer.zero_grad()\n",
    "\n",
    "            # Inner loop (task-specific optimization)\n",
    "            with higher.innerloop_ctx(model, meta_optimizer, copy_initial_weights=False) as (fmodel, diffopt):\n",
    "                for _ in range(inner_steps):\n",
    "                    train_preds = fmodel(torch.tensor(task['X_train'], dtype=torch.float32))\n",
    "                    task_loss = nn.CrossEntropyLoss()(train_preds, torch.tensor(task['y_train'], dtype=torch.long))\n",
    "                    diffopt.step(task_loss)\n",
    "\n",
    "                # Validation (meta-objective)\n",
    "                val_preds = fmodel(torch.tensor(task['X_val'], dtype=torch.float32))\n",
    "                val_loss = nn.CrossEntropyLoss()(val_preds, torch.tensor(task['y_val'], dtype=torch.long))\n",
    "                \n",
    "                # Meta-gradient accumulation\n",
    "                val_loss.backward()\n",
    "                total_meta_loss += val_loss.item()\n",
    "\n",
    "            # Meta-optimizer step\n",
    "            meta_optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{meta_epochs}, Meta-Loss: {total_meta_loss/len(tasks)}\")\n",
    "\n",
    "# Initialize the model and run the MAML loop\n",
    "model = SimpleNet()\n",
    "train_maml(model, tasks)  # 'tasks' are created using the create_few_shot_tasks() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93cb5a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss after Fine-Tuning: 0.7956761717796326\n"
     ]
    }
   ],
   "source": [
    "def test_maml(model, task, inner_lr=0.01, inner_steps=5):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=inner_lr)\n",
    "    \n",
    "    # Inner loop (fine-tune on new task)\n",
    "    for _ in range(inner_steps):\n",
    "        train_preds = model(torch.tensor(task['X_train'], dtype=torch.float32))\n",
    "        task_loss = nn.CrossEntropyLoss()(train_preds, torch.tensor(task['y_train'], dtype=torch.long))\n",
    "        optimizer.zero_grad()\n",
    "        task_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(torch.tensor(task['X_val'], dtype=torch.float32))\n",
    "        val_loss = nn.CrossEntropyLoss()(val_preds, torch.tensor(task['y_val'], dtype=torch.long))\n",
    "        print(f\"Validation Loss after Fine-Tuning: {val_loss.item()}\")\n",
    "\n",
    "# Example: Test on a new task\n",
    "test_maml(model, tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3d4c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Meta Loss: 0.6257\n",
      "Epoch 2/100, Meta Loss: 0.6257\n",
      "Epoch 3/100, Meta Loss: 0.6125\n",
      "Epoch 4/100, Meta Loss: 0.5998\n",
      "Epoch 5/100, Meta Loss: 0.5884\n",
      "Epoch 6/100, Meta Loss: 0.5777\n",
      "Epoch 7/100, Meta Loss: 0.5677\n",
      "Epoch 8/100, Meta Loss: 0.5586\n",
      "Epoch 9/100, Meta Loss: 0.5504\n",
      "Epoch 10/100, Meta Loss: 0.5434\n",
      "Epoch 11/100, Meta Loss: 0.5370\n",
      "Epoch 12/100, Meta Loss: 0.5307\n",
      "Epoch 13/100, Meta Loss: 0.5249\n",
      "Epoch 14/100, Meta Loss: 0.5196\n",
      "Epoch 15/100, Meta Loss: 0.5143\n",
      "Epoch 16/100, Meta Loss: 0.5092\n",
      "Epoch 17/100, Meta Loss: 0.5042\n",
      "Epoch 18/100, Meta Loss: 0.4992\n",
      "Epoch 19/100, Meta Loss: 0.4945\n",
      "Epoch 20/100, Meta Loss: 0.4894\n",
      "Epoch 21/100, Meta Loss: 0.4846\n",
      "Epoch 22/100, Meta Loss: 0.4798\n",
      "Epoch 23/100, Meta Loss: 0.4749\n",
      "Epoch 24/100, Meta Loss: 0.4700\n",
      "Epoch 25/100, Meta Loss: 0.4649\n",
      "Epoch 26/100, Meta Loss: 0.4598\n",
      "Epoch 27/100, Meta Loss: 0.4547\n",
      "Epoch 28/100, Meta Loss: 0.4496\n",
      "Epoch 29/100, Meta Loss: 0.4446\n",
      "Epoch 30/100, Meta Loss: 0.4397\n",
      "Epoch 31/100, Meta Loss: 0.4347\n",
      "Epoch 32/100, Meta Loss: 0.4297\n",
      "Epoch 33/100, Meta Loss: 0.4248\n",
      "Epoch 34/100, Meta Loss: 0.4198\n",
      "Epoch 35/100, Meta Loss: 0.4149\n",
      "Epoch 36/100, Meta Loss: 0.4098\n",
      "Epoch 37/100, Meta Loss: 0.4047\n",
      "Epoch 38/100, Meta Loss: 0.3995\n",
      "Epoch 39/100, Meta Loss: 0.3945\n",
      "Epoch 40/100, Meta Loss: 0.3896\n",
      "Epoch 41/100, Meta Loss: 0.3848\n",
      "Epoch 42/100, Meta Loss: 0.3801\n",
      "Epoch 43/100, Meta Loss: 0.3754\n",
      "Epoch 44/100, Meta Loss: 0.3707\n",
      "Epoch 45/100, Meta Loss: 0.3661\n",
      "Epoch 46/100, Meta Loss: 0.3616\n",
      "Epoch 47/100, Meta Loss: 0.3573\n",
      "Epoch 48/100, Meta Loss: 0.3534\n",
      "Epoch 49/100, Meta Loss: 0.3494\n",
      "Epoch 50/100, Meta Loss: 0.3461\n",
      "Epoch 51/100, Meta Loss: 0.3425\n",
      "Epoch 52/100, Meta Loss: 0.3407\n",
      "Epoch 53/100, Meta Loss: 0.3371\n",
      "Epoch 54/100, Meta Loss: 0.3334\n",
      "Epoch 55/100, Meta Loss: 0.3296\n",
      "Epoch 56/100, Meta Loss: 0.3257\n",
      "Epoch 57/100, Meta Loss: 0.3211\n",
      "Epoch 58/100, Meta Loss: 0.3175\n",
      "Epoch 59/100, Meta Loss: 0.3132\n",
      "Epoch 60/100, Meta Loss: 0.3089\n",
      "Epoch 61/100, Meta Loss: 0.3043\n",
      "Epoch 62/100, Meta Loss: 0.2994\n",
      "Epoch 63/100, Meta Loss: 0.2944\n",
      "Epoch 64/100, Meta Loss: 0.2894\n",
      "Epoch 65/100, Meta Loss: 0.2842\n",
      "Epoch 66/100, Meta Loss: 0.2791\n",
      "Epoch 67/100, Meta Loss: 0.2738\n",
      "Epoch 68/100, Meta Loss: 0.2686\n",
      "Epoch 69/100, Meta Loss: 0.2637\n",
      "Epoch 70/100, Meta Loss: 0.2590\n",
      "Epoch 71/100, Meta Loss: 0.2543\n",
      "Epoch 72/100, Meta Loss: 0.2497\n",
      "Epoch 73/100, Meta Loss: 0.2445\n",
      "Epoch 74/100, Meta Loss: 0.2392\n",
      "Epoch 75/100, Meta Loss: 0.2339\n",
      "Epoch 76/100, Meta Loss: 0.2287\n",
      "Epoch 77/100, Meta Loss: 0.2234\n",
      "Epoch 78/100, Meta Loss: 0.2183\n",
      "Epoch 79/100, Meta Loss: 0.2132\n",
      "Epoch 80/100, Meta Loss: 0.2079\n",
      "Epoch 81/100, Meta Loss: 0.2030\n",
      "Epoch 82/100, Meta Loss: 0.1983\n",
      "Epoch 83/100, Meta Loss: 0.1934\n",
      "Epoch 84/100, Meta Loss: 0.1886\n",
      "Epoch 85/100, Meta Loss: 0.1841\n",
      "Epoch 86/100, Meta Loss: 0.1798\n",
      "Epoch 87/100, Meta Loss: 0.1756\n",
      "Epoch 88/100, Meta Loss: 0.1715\n",
      "Epoch 89/100, Meta Loss: 0.1676\n",
      "Epoch 90/100, Meta Loss: 0.1644\n",
      "Epoch 91/100, Meta Loss: 0.1605\n",
      "Epoch 92/100, Meta Loss: 0.1568\n",
      "Epoch 93/100, Meta Loss: 0.1531\n",
      "Epoch 94/100, Meta Loss: 0.1494\n",
      "Epoch 95/100, Meta Loss: 0.1459\n",
      "Epoch 96/100, Meta Loss: 0.1424\n",
      "Epoch 97/100, Meta Loss: 0.1389\n",
      "Epoch 98/100, Meta Loss: 0.1355\n",
      "Epoch 99/100, Meta Loss: 0.1325\n",
      "Epoch 100/100, Meta Loss: 0.1294\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Define the model (a simple neural network)\n",
    "class MAMLModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MAMLModel, self).__init__()\n",
    "        self.fc1 = layers.Dense(40, activation='relu')\n",
    "        self.fc2 = layers.Dense(20, activation='relu')\n",
    "        self.fc3 = layers.Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.fc2(x)\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Meta-learning loop for MAML\n",
    "def maml_train_step(model, optimizer, task_data, inner_steps=1, alpha=0.01, beta=0.001):\n",
    "    meta_gradients = [tf.zeros_like(var) for var in model.trainable_variables]  # Initialize empty gradients for meta-update\n",
    "    \n",
    "    for X_train, y_train, X_val, y_val in task_data:\n",
    "        # Reshape y_train and y_val to match the shape of model output\n",
    "        y_train = np.reshape(y_train, (-1, 1))\n",
    "        y_val = np.reshape(y_val, (-1, 1))\n",
    "\n",
    "        # Save initial weights for meta-update (deep copy to avoid overwriting)\n",
    "        original_weights = [w.numpy() for w in model.trainable_variables]\n",
    "\n",
    "        # Inner loop: task-specific adaptation\n",
    "        for _ in range(inner_steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model(X_train)\n",
    "                loss = tf.keras.losses.binary_crossentropy(y_train, predictions, from_logits=False)\n",
    "\n",
    "            # Compute task-specific gradients\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            updated_weights = [w - alpha * g for w, g in zip(model.trainable_variables, grads)]\n",
    "            \n",
    "            # Manually assign the updated weights to the model's trainable variables\n",
    "            for var, updated in zip(model.trainable_variables, updated_weights):\n",
    "                var.assign(updated)\n",
    "\n",
    "        # Compute validation loss after task-specific adaptation\n",
    "        with tf.GradientTape() as tape:\n",
    "            val_predictions = model(X_val)\n",
    "            val_loss = tf.keras.losses.binary_crossentropy(y_val, val_predictions, from_logits=False)\n",
    "        \n",
    "        # Compute gradients of the validation loss (meta-gradients)\n",
    "        task_gradients = tape.gradient(val_loss, model.trainable_variables)\n",
    "        \n",
    "        # Check for None gradients and handle them (skip those without valid gradients)\n",
    "        task_gradients = [g if g is not None else tf.zeros_like(var) for g, var in zip(task_gradients, model.trainable_variables)]\n",
    "        \n",
    "        # Accumulate task gradients for meta-update\n",
    "        meta_gradients = [meta_grad + task_grad for meta_grad, task_grad in zip(meta_gradients, task_gradients)]\n",
    "\n",
    "        # Restore the model's original weights (before task-specific updates)\n",
    "        for var, orig in zip(model.trainable_variables, original_weights):\n",
    "            var.assign(orig)\n",
    "\n",
    "    # Filter out None gradients and apply the accumulated meta-gradients\n",
    "    meta_gradients = [(g, v) for g, v in zip(meta_gradients, model.trainable_variables) if g is not None]\n",
    "    if meta_gradients:  # Only apply gradients if they exist\n",
    "        optimizer.apply_gradients(meta_gradients)\n",
    "\n",
    "    return tf.reduce_mean(val_loss)\n",
    "\n",
    "# Dummy data for few-shot learning (replace with real tasks)\n",
    "def generate_few_shot_tasks(num_tasks, num_samples):\n",
    "    tasks = []\n",
    "    for _ in range(num_tasks):\n",
    "        X_train = np.random.randn(num_samples, 30)  # 30 features\n",
    "        y_train = np.random.randint(0, 2, num_samples)\n",
    "        X_val = np.random.randn(num_samples, 30)\n",
    "        y_val = np.random.randint(0, 2, num_samples)\n",
    "        tasks.append((X_train, y_train, X_val, y_val))\n",
    "    return tasks\n",
    "\n",
    "# Initialize model and optimizer\n",
    "maml_model = MAMLModel()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Generate tasks and perform meta-learning training\n",
    "num_tasks = 10\n",
    "task_data = generate_few_shot_tasks(num_tasks, 5)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    meta_loss = maml_train_step(maml_model, optimizer, task_data)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Meta Loss: {meta_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95d87374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.4980 - loss: 0.9684\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5663 - loss: 0.7143\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5600 - loss: 0.6463\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7838 - loss: 0.5098\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9371 - loss: 0.2655\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9695 - loss: 0.1324\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9994 - loss: 0.0379\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0174\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0097\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Loss: 0.0045623742043972015, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# Dummy data generation\n",
    "def generate_multimodal_data(num_samples):\n",
    "    # Simulating image data (e.g., 64x64 RGB images)\n",
    "    image_data = np.random.rand(num_samples, 64, 64, 3)\n",
    "    # Simulating text data (e.g., 10 words per sample, with each word represented by an integer index)\n",
    "    text_data = np.random.randint(1, 1000, size=(num_samples, 10))  # Vocabulary size of 1000\n",
    "    # Simulating labels (0 or 1 for binary classification)\n",
    "    labels = np.random.randint(0, 2, num_samples)\n",
    "    return image_data, text_data, labels\n",
    "\n",
    "# Multi-Modal Model Definition\n",
    "def create_multimodal_model():\n",
    "    # Image branch\n",
    "    image_input = layers.Input(shape=(64, 64, 3))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    image_features = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "    # Text branch\n",
    "    text_input = layers.Input(shape=(10,))\n",
    "    y = layers.Embedding(input_dim=1000, output_dim=64)(text_input)  # Embedding for text data\n",
    "    y = layers.GlobalAveragePooling1D()(y)\n",
    "    text_features = layers.Dense(64, activation='relu')(y)\n",
    "\n",
    "    # Combine features from both branches\n",
    "    combined = layers.concatenate([image_features, text_features])\n",
    "    z = layers.Dense(64, activation='relu')(combined)\n",
    "    output = layers.Dense(1, activation='sigmoid')(z)  # Binary classification output\n",
    "\n",
    "    model = Model(inputs=[image_input, text_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Generate dummy data\n",
    "num_samples = 1000\n",
    "image_data, text_data, labels = generate_multimodal_data(num_samples)\n",
    "\n",
    "# Create the model\n",
    "multimodal_model = create_multimodal_model()\n",
    "multimodal_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "multimodal_model.fit([image_data, text_data], labels, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = multimodal_model.evaluate([image_data, text_data], labels)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f923087c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5136 - loss: 0.8025\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4852 - loss: 0.7024\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7363 - loss: 0.6229\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9001 - loss: 0.3892\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9605 - loss: 0.1775\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0544\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0150\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0082\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0051\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5089 - loss: 1.3521\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6584 - loss: 0.6519\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6648 - loss: 0.6120\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7893 - loss: 0.4795\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9478 - loss: 0.1900\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0668\n",
      "Iteration 1 - Loss: 0.0649, Accuracy: 0.9980\n",
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5118 - loss: 0.8624\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6496 - loss: 0.6405\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8513 - loss: 0.3904\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9793 - loss: 0.1280\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0207\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0046\n",
      "Iteration 2 - Loss: 0.0049, Accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4931 - loss: 1.0541\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.6977 - loss: 0.6609\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7816 - loss: 0.5682\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8961 - loss: 0.3860\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9398 - loss: 0.1842\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9932 - loss: 0.0619\n",
      "Iteration 3 - Loss: 0.0624, Accuracy: 0.9970\n",
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4692 - loss: 0.9377\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7890 - loss: 0.5828\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9007 - loss: 0.3210\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9579 - loss: 0.1605\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0286\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0111\n",
      "Iteration 4 - Loss: 0.0110, Accuracy: 1.0000\n",
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4658 - loss: 1.1247\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7615 - loss: 0.5602\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9028 - loss: 0.3097\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9957 - loss: 0.0663\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 1.0000 - loss: 0.0140\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Iteration 5 - Loss: 0.0034, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple multi-modal model (as defined previously)\n",
    "def create_multimodal_model():\n",
    "    # Image branch\n",
    "    image_input = layers.Input(shape=(64, 64, 3))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    image_features = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "    # Text branch\n",
    "    text_input = layers.Input(shape=(10,))\n",
    "    y = layers.Embedding(input_dim=1000, output_dim=64)(text_input)  # Embedding for text data\n",
    "    y = layers.GlobalAveragePooling1D()(y)\n",
    "    text_features = layers.Dense(64, activation='relu')(y)\n",
    "\n",
    "    # Combine features from both branches\n",
    "    combined = layers.concatenate([image_features, text_features])\n",
    "    z = layers.Dense(64, activation='relu')(combined)\n",
    "    output = layers.Dense(1, activation='sigmoid')(z)  # Binary classification output\n",
    "\n",
    "    model = Model(inputs=[image_input, text_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Simulate feedback and re-training process\n",
    "def self_improvement_training(model, num_iterations=5):\n",
    "    for iteration in range(num_iterations):\n",
    "        # Generate new data (could be augmented based on previous errors)\n",
    "        image_data, text_data, labels = generate_multimodal_data(1000)  # New data for re-training\n",
    "        \n",
    "        # Train the model on the new data\n",
    "        model.fit([image_data, text_data], labels, epochs=5, batch_size=32)\n",
    "\n",
    "        # Evaluate the model and simulate feedback\n",
    "        loss, accuracy = model.evaluate([image_data, text_data], labels)\n",
    "        print(f\"Iteration {iteration + 1} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Simulate feedback mechanism (adjust learning rate or model complexity based on accuracy)\n",
    "        if accuracy < 0.75:  # Arbitrary threshold for this example\n",
    "            print(\"Accuracy below threshold, adjusting learning rate.\")\n",
    "            # Reduce learning rate or modify model (e.g., add more layers, change architecture, etc.)\n",
    "            tf.keras.backend.set_value(model.optimizer.lr, 0.0001)  # Adjust learning rate\n",
    "\n",
    "# Generate initial dummy data\n",
    "initial_image_data, initial_text_data, initial_labels = generate_multimodal_data(1000)\n",
    "\n",
    "# Create and compile the model\n",
    "multimodal_model = create_multimodal_model()\n",
    "multimodal_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Initial training\n",
    "multimodal_model.fit([initial_image_data, initial_text_data], initial_labels, epochs=10, batch_size=32)\n",
    "\n",
    "# Self-improvement training\n",
    "self_improvement_training(multimodal_model, num_iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c93b6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.5361 - loss: 0.9480 - val_accuracy: 0.4810 - val_loss: 0.6871\n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5145 - loss: 0.6885 - val_accuracy: 0.9360 - val_loss: 0.6582\n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8489 - loss: 0.6482 - val_accuracy: 0.7790 - val_loss: 0.5425\n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8423 - loss: 0.5022 - val_accuracy: 0.9590 - val_loss: 0.2693\n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9551 - loss: 0.2409 - val_accuracy: 0.9540 - val_loss: 0.1683\n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9862 - loss: 0.1045 - val_accuracy: 1.0000 - val_loss: 0.0329\n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0115\n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0310\n",
      "Loss: 0.03291087597608566, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple multi-modal model (as defined previously)\n",
    "def create_multimodal_model():\n",
    "    # Image branch\n",
    "    image_input = layers.Input(shape=(64, 64, 3))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    image_features = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "    # Text branch\n",
    "    text_input = layers.Input(shape=(10,))\n",
    "    y = layers.Embedding(input_dim=1000, output_dim=64)(text_input)  # Embedding for text data\n",
    "    y = layers.GlobalAveragePooling1D()(y)\n",
    "    text_features = layers.Dense(64, activation='relu')(y)\n",
    "\n",
    "    # Combine features from both branches\n",
    "    combined = layers.concatenate([image_features, text_features])\n",
    "    z = layers.Dense(64, activation='relu')(combined)\n",
    "    output = layers.Dense(1, activation='sigmoid')(z)  # Binary classification output\n",
    "\n",
    "    model = Model(inputs=[image_input, text_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Dummy data generation\n",
    "def generate_multimodal_data(num_samples):\n",
    "    image_data = np.random.rand(num_samples, 64, 64, 3)\n",
    "    text_data = np.random.randint(1, 1000, size=(num_samples, 10))\n",
    "    labels = np.random.randint(0, 2, num_samples)\n",
    "    return image_data, text_data, labels\n",
    "\n",
    "# Create a TensorFlow Dataset\n",
    "def create_tf_dataset(num_samples, batch_size=32):\n",
    "    image_data, text_data, labels = generate_multimodal_data(num_samples)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((image_data, text_data), labels))  # Yield tuple of inputs and labels\n",
    "    dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "multimodal_model = create_multimodal_model()\n",
    "multimodal_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create the training dataset\n",
    "train_dataset = create_tf_dataset(1000, batch_size=32)\n",
    "\n",
    "# Model Checkpointing\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='multimodal_model.weights.h5',  # Updated to end with .weights.h5\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model with the scalable dataset\n",
    "multimodal_model.fit(train_dataset, epochs=10, validation_data=train_dataset, callbacks=[checkpoint_callback])\n",
    "\n",
    "# Load the best model (if needed)\n",
    "multimodal_model.load_weights('multimodal_model.weights.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = multimodal_model.evaluate(train_dataset)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "776f1f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:51.332923: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4928 - loss: 1.2158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:52.612317: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.4943 - loss: 1.1999 - val_accuracy: 0.5220 - val_loss: 0.7004\n",
      "Epoch 2/10\n",
      "\u001b[1m 4/32\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3913 - loss: 0.7425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:52.927551: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4904 - loss: 0.7087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:53.634303: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4935 - loss: 0.7076 - val_accuracy: 0.5220 - val_loss: 0.6570\n",
      "Epoch 3/10\n",
      "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5674 - loss: 0.6472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:53.885035: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6202 - loss: 0.6393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:54.561617: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.6236 - loss: 0.6387 - val_accuracy: 0.9040 - val_loss: 0.5211\n",
      "Epoch 4/10\n",
      "\u001b[1m 4/32\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8125 - loss: 0.5279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:54.802384: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8742 - loss: 0.4810"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:55.497750: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8741 - loss: 0.4791 - val_accuracy: 0.9230 - val_loss: 0.2953\n",
      "Epoch 5/10\n",
      "\u001b[1m 4/32\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9368 - loss: 0.2974"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:55.754966: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9478 - loss: 0.2505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:56.489875: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9477 - loss: 0.2490 - val_accuracy: 0.9840 - val_loss: 0.1088\n",
      "Epoch 6/10\n",
      "\u001b[1m 4/32\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9980 - loss: 0.1068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:56.723533: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9905 - loss: 0.0978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:57.428154: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9901 - loss: 0.0977 - val_accuracy: 0.9990 - val_loss: 0.0473\n",
      "Epoch 7/10\n",
      "\u001b[1m 4/32\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9980 - loss: 0.0563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:57.665855: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9968 - loss: 0.0525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:58.383506: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9968 - loss: 0.0524 - val_accuracy: 1.0000 - val_loss: 0.0294\n",
      "Epoch 8/10\n",
      "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0358"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:58.624822: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:59.321395: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0281 - val_accuracy: 1.0000 - val_loss: 0.0127\n",
      "Epoch 9/10\n",
      "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0139"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:18:59.549566: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:19:00.266205: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.0066\n",
      "Epoch 10/10\n",
      "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0060"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:19:00.519162: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0058"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:19:01.318063: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "\u001b[1m18/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0282"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:19:01.554014: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0284\n",
      "Loss: 0.02944675274193287, Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 02:19:01.830851: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple multi-modal model (as defined previously)\n",
    "def create_multimodal_model():\n",
    "    # Image branch\n",
    "    image_input = layers.Input(shape=(64, 64, 3))\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    image_features = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "    # Text branch\n",
    "    text_input = layers.Input(shape=(10,))\n",
    "    y = layers.Embedding(input_dim=1000, output_dim=64)(text_input)  # Embedding for text data\n",
    "    y = layers.GlobalAveragePooling1D()(y)\n",
    "    text_features = layers.Dense(64, activation='relu')(y)\n",
    "\n",
    "    # Combine features from both branches\n",
    "    combined = layers.concatenate([image_features, text_features])\n",
    "    z = layers.Dense(64, activation='relu')(combined)\n",
    "    output = layers.Dense(1, activation='sigmoid')(z)  # Binary classification output\n",
    "\n",
    "    model = Model(inputs=[image_input, text_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Dummy data generation\n",
    "def generate_multimodal_data(num_samples):\n",
    "    image_data = np.random.rand(num_samples, 64, 64, 3)\n",
    "    text_data = np.random.randint(1, 1000, size=(num_samples, 10))\n",
    "    labels = np.random.randint(0, 2, num_samples)\n",
    "    return image_data, text_data, labels\n",
    "\n",
    "# Create a TensorFlow Dataset\n",
    "def create_tf_dataset(num_samples, batch_size=32):\n",
    "    image_data, text_data, labels = generate_multimodal_data(num_samples)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((image_data, text_data), labels))\n",
    "    dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Set up the distribution strategy\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    # Initialize the model and optimizer\n",
    "    multimodal_model = create_multimodal_model()\n",
    "    multimodal_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create the training dataset\n",
    "train_dataset = create_tf_dataset(1000, batch_size=32)\n",
    "\n",
    "# Model Checkpointing\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='multimodal_model.weights.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model with the scalable dataset\n",
    "multimodal_model.fit(train_dataset, epochs=10, validation_data=train_dataset, callbacks=[checkpoint_callback])\n",
    "\n",
    "# Load the best model (if needed)\n",
    "multimodal_model.load_weights('multimodal_model.weights.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = multimodal_model.evaluate(train_dataset)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f14bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
